<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Alexander Sun</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="https://cal-cs184-student.github.io/hw-webpages-sp24-llejj/">HERE</a></h2>

<br><br>


<div>

<h2 align="middle">Overview</h2>
<p>
    In this assignment, we implement pathtracing, which is a technique to render photorealistc images by calculating a steady-state particle model of light. Our model is described by the Rendering Equation, which reveals that our render should be the sum of all paths that light can take to our camera sensor, partitioned by the number of bounces their path took. To compute this efficiently, we use techniques such as BVH to accelerate intersection detection, Monte Carlo integration, Russian Roulette, and adaptive sampling. 
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
    At a high level, the rendering pipeline samples a bunch of rays per pixel to determine how much light passes through the pixel. Thus, for each point in image space, we need to be able to generate the corresponding ray in world space. And once we have a ray, we need to be able to find its first primitive intersection (so that we can calculate the radiance at that intersection).

    To generate a ray, I take as input a coordinate in image space. I transform that to a coordinate on the image sensor by finding the x and y bounds of the sensor, then using the image space coordinates to lerp between the bounds. Then, I append a z-value of -1 to get a ray in camera space. Lastly, I use the camera-to-world rotation matrix to get the ray in world space.
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
    I used the MÃ¶ller-Trumbore intersection algorithm. Given a ray, I want to know if it intersects, and if so, to record information about the intersection. First, I check if the ray is parallel to the triangle plane, and if so, return false. Otherwise, I compute the barycentric coordinates of the intersection. Along with the range of valid t-values, this determines whether the ray intersects the triangle. The surface normal at the intersection can also be computed using barycentric interpolation. Lastly, I update the relevant variables, such as max_t, n, bsdf, etc.
</p>
<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/CBspheres.png" align="middle" width="400px"/>
        <figcaption>CBspheres.dae</figcaption>
      </td>
      <td>
        <img src="./images/banana.png" align="middle" width="400px"/>
        <figcaption>banana.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/CBempty.png" align="middle" width="400px"/>
        <figcaption>CBempty.dae</figcaption>
      </td>
      <td>
        <img src="images/CBgems.png" align="middle" width="400px"/>
        <figcaption>CBgems.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
  I implement construct_bvh() recursively. I take as input a list of primitives, an output the root node of the BVH. As a base case, I return a leaf node if the number of primitives is below max_leaf_size. 
  
  Otherwise, I decide to split along the longest axis of the bounding box. Then, to split along this axis, I sort the set of primitives by their centroids' relevant component. Once sorted, I split at the median primitive. For each side of the split, I call construct_bvh() to create a child node.
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/maxplanck.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae</figcaption>
      </td>
      <td>
        <img src="images/wall-e.png" align="middle" width="400px"/>
        <figcaption>wall-e.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/CBlucy.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae</figcaption>
      </td>
      <td>
        <img src="images/dragon.png" align="middle" width="400px"/>
        <figcaption>dragon.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
    I rendered my images on my laptop. For cow.dae, which has 5856 primitives, the rendering BVH acceleration took 0.0751 seconds. On the other hand, without BVH acceleration took 30 seconds. 

    For maxplanck.dae, which has 50801 primitives, the rendering BVH acceleration took 0.0954 seconds. On the other hand, without BVH acceleration took 234 seconds.

    It is clear that BVH acceleration results in insane runtime improvements and scales much better.
</p>
<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    To implement estimate_direct_lighting_hemisphere(), I initialize L_out=(0, 0, 0). Then, I loop num_sample times. For each iteration, I call sample a direction $wi$ on the hemisphere uniformly. I find the incoming light from that direction by finding the primitive intersection of wi, then taking the emission at that intersection. Lastly, I add this iteration's contribution to the Monte Carlo integral L_out, computed with the reflection equation.
</p><p>
    To implement estimate_direct_lighting_importance(), I initialize L_out=(0, 0, 0). Then, I loop over all the light sources. For each point light, I take a single sample, compute the ray between p_hit and the light source, and check if there are any intersections (light source blocked). If not, I add the point light's contribution to the Monte Carlo integral L_out. For each area light, I take ns_area_light samples. For each sample, I call sample_L(), test for intersection, and use reflection equation. 
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/part_3_H1.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
      <td>
        <img src="images/part_3_L1.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/part_3_H2.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
      <td>
        <img src="images/part_3_L2.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_3_l1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_3_l4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_3_l16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_3_l64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
    We see that as we take more light rays, the noise in soft shadows decreases. This is because the noise in the Monte Carlo estimator is proportional to the variance of the integrand, so the noise is much more noticable for soft shadows. And we expect the noise to be proportional to $\frac{1}{\sqrt{n}}$.
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    Uniform hemisphere sampling has more noise than lighting sampling. This is because, mathematically, lighting sampling implements importance sampling in Monte Carlo integration, which reduces noise. We can see this in the renderings of CBbunny.dae and CBspheres_lambertian.dae. The walls of the rooms with uniform hemisphere sampling are noticably more grainy. In addition, uniform hemisphere sampling is unable to handle point light sources, while lighting sampling is perfectly fine. 
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    I implement at_least_one_bounce_radiance() recursively. I take as input an incoming ray, its intersection point, and max_ray_depth (this is a helper variable for recursion). I output the radiance along the input ray direction (but flipped, away from the intersection). As a base case, if max_ray_depth = 1, I return one_bounce_radiance(). Otherwise, I initialize L_out = one_bounce_radiance(). This accounts for the direct lighting. To account for the indirect lighting, I sample n direction, which represents a possible path that the indirect illumation may have taken, and trace to its intersection point. I call at_least_one_bounce_radiance(max_ray_depth = max_ray_depth - 1) at this new intersection, which I use as the value of L_in in the reflection equation. Lastly, I add the result of the reflection equation to L_out and return L_out. <br><br>

    I also implemented Russian Roulette, which is a technique for unbiased termination in our rendering equation. The way I did this, is to only recursively call at_least_one_bounce_radiance() with probability $cpdf$, and to divide the result of such a recursive call by $cpdf$. As an edge case, for max_ray_depth > 1, I always compute at least the first bounce of indirect illumination. 
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/global_example_1.png" align="middle" width="400px"/>
        <figcaption>dragon.dae</figcaption>
      </td>
      <td>
        <img src="images/global_example_2.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_4_direct.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4_indirect.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    We see that there is much more total light from direct illumination compared to indirect illumination. In addition, the indirect illumination is more evenly spread than the direct illumination. 
</p>
<br>


<p>
  Below, I have renders of CBbunny.dae at 1024 samples per pixel: 
</p>
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <th>
        <b>isAccumBounces = false</b>
      </th>
      <th>
        <b>isAccumBounces = true</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/bunny_0-f.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0, isAccumBounces = false</figcaption>
      </td>
      <td>
        <img src="images/bunny_0-t.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0, isAccumBounces = true</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_1-f.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1, isAccumBounces = false</figcaption>
      </td>
      <td>
        <img src="images/bunny_1-t.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1, isAccumBounces = true</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_2-f.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2, isAccumBounces = false</figcaption>
      </td>
      <td>
        <img src="images/bunny_2-t.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2, isAccumBounces = true</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_3-f.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3, isAccumBounces = false</figcaption>
      </td>
      <td>
        <img src="images/bunny_3-t.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3, isAccumBounces = true</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_4-f.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4, isAccumBounces = false</figcaption>
      </td>
      <td>
        <img src="images/bunny_4-t.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4, isAccumBounces = true</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_5-f.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 5, isAccumBounces = false</figcaption>
      </td>
      <td>
        <img src="images/bunny_4-t.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 5, isAccumBounces = true</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
  For isAccumBounces = false, I notice that the 2nd bounce of light is brighter on the bottom side of the rabbit, which was not directly illuminated. This contributes to giving the rendered image better ambient lighting. The 3rd bounce of light is pretty dark, so it only contributes to fine details in lighting.  
</p><p>
  For isAccumBounces = true, I notice that for larger m, the rendering gets brighter, which makes sense since additional bounces can only increase the amount of lighting. I see that the most drastic change is when m=2, since the rabbit's bottom side gets noticably brighter. 
</p>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, 4, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_rr0.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_rr1.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_rr2.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_rr3.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_rr4.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_rr100.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    In the above renderings, I implemented Russian Roulette. I notice that, for larger values of max_ray_depth, the images look more accurate. This makes sense because we are better approximating global illumination, and if we were to set max_ray_depth = $\inf$, then our rendering would be unbiased, meaning that its expected value would be the true rendering.
</p>
<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_4_1spp.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (blob.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4_2spp.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (blob.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4_4spp.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (blob.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4_8spp.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (blob.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4_16spp.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (blob.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4_64spp.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (blob.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4_1024spp.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (blob.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    I rendered the above images with Russian Roulette. I notice that, as we take more samples per pixel, the noise decreases. Theoretically, without a max_ray_depth, our estimator would be unbiased, so as the noise decreases we would converge toward the true solution to the rendering equation.
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
    Adaptive sampling is a way to sample different numbers of rays per pixel, depending on their rate of convergence. Intuitively, if a pixel converges fast, we don't need to take as many samples. To implement this, I check every samplesPerBatch samples, to see whether the pixel has converged or not. This convergence is checked by comparing the standard error of our estimate to a threshold. We can compute this standard error by keeping a running sum of the sample illuminances and the squared illuminances, which are used in the formula for standard error. 
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_5_scene1.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_5_scene1_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_5_scene2.png" align="middle" width="400px"/>
        <figcaption>Rendered image (dragon.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_5_scene2_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (dragon.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
